{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "#Create an empty dictionary and assign it to html_tables\n",
    "html_tables = {}\n",
    "\n",
    "# For every table in the datasets folder...\n",
    "for table_name in os.listdir('datasets'):\n",
    "    #this is the path to the file\n",
    "    table_path = f'datasets/{table_name}'\n",
    "    # Open as a python file in read-only mode ('r')\n",
    "    table_file = open(table_path,'r')\n",
    "    # Read the contents of the file into 'html'\n",
    "    html = BeautifulSoup(table_file.read())\n",
    "    # Find 'news-table' in the Soup and load it into 'html_table'\n",
    "    html_table = html.find(id='news-table')\n",
    "    # Add the table to html_tables dictionary\n",
    "    html_tables[table_name] = html_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read one single day of headlines \n",
    "tsla = html_tables['tsla_22sep.html']\n",
    "\n",
    "# Get all the table rows tagged in HTML with <tr> into 'tesla_tr'\n",
    "tsla_tr = tsla.find_all('tr')\n",
    "\n",
    "# For each row...\n",
    "for i, table_row in enumerate(tsla_tr):\n",
    "    # Read the text of the element 'a' into 'link_text'\n",
    "    link_text = table_row.a.get_text()\n",
    "    # Read the text of the element 'td' into 'data_text'\n",
    "    data_text = table_row.td.get_text()\n",
    "    # Print the count\n",
    "    print(f'File number {i+1}:')\n",
    "    # Print the contents of 'link_text' and 'data_text' \n",
    "    print(link_text)\n",
    "    print(data_text)\n",
    "    # The following exits the loop after four rows to prevent spamming the notebook\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold the parsed news into a list parsed_news\n",
    "parsed_news = []\n",
    "\n",
    "# Iterate through the news\n",
    "for file_name, news_table in html_tables.items():\n",
    "    # Iterate through all tr tags in 'news_table'\n",
    "    for x in news_table.findAll('tr'):\n",
    "        # Read the text from the tr tag into text\n",
    "        text = x.get_text() \n",
    "        # Split the text in the td tag into a list \n",
    "        date_scrape = x.td.text.split()\n",
    "        # If the length of 'date_scrape' is 1, load 'time' as the only element\n",
    "        # If not, load 'date' as the 1st element [0] and 'time' as the second [1]\n",
    "        if len(date_scrape) == 1:\n",
    "            time = date_scrape[0]\n",
    "        else:\n",
    "            time = date_scrape[1]\n",
    "            date = date_scrape[0]\n",
    "\n",
    "\n",
    "            \n",
    "        # Extract the ticker from the file name, get the string up to the 1st '_'  \n",
    "        ticker = file_name.split('_')[0]\n",
    "        \n",
    "        # Append ticker, date, time and headline (x.a.get_text()) as a list to the 'parsed_news' list\n",
    "        parsed_news.append([ticker, date, time, x.a.get_text()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK VADER for sentiment analysis\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# New words and their values\n",
    "new_words = {\n",
    "    'crushes': 10,\n",
    "    'beats': 5,\n",
    "    'misses': -5,\n",
    "    'trouble': -10,\n",
    "    'falls': -100,\n",
    "}\n",
    "# Instantiate the sentiment intensity analyzer with the existing lexicon\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Update the lexicon\n",
    "vader.lexicon.update(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Use these column names: 'ticker', 'date', 'time', 'headline'\n",
    "columns = ['ticker', 'date', 'time', 'headline']\n",
    "\n",
    "# Convert the list of lists into a DataFrame\n",
    "scored_news = pd.DataFrame(parsed_news, columns=columns)\n",
    "\n",
    "# Iterate through the headlines and get the polarity scores\n",
    "scores = [vader.polarity_scores(headline) for headline in scored_news['headline'].values]\n",
    "\n",
    "# Convert the list of dicts into a DataFrame\n",
    "scores_df = pd.DataFrame(scores)\n",
    "\n",
    "# Join the DataFrames\n",
    "scored_news = scored_news.join(scores_df)\n",
    "\n",
    "# Convert the date column from string to datetime\n",
    "scored_news['date'] = pd.to_datetime(scored_news.date).dt.date\n",
    "\n",
    "scored_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Group by date and ticker columns from scored_news and calculate the mean\n",
    "mean_c = scored_news.groupby(['date','ticker']).mean()\n",
    "\n",
    "# Unstack the column ticker\n",
    "mean_c = mean_c.unstack(level=-1)\n",
    "\n",
    "# Get the cross-section of compound in the 'columns' axis\n",
    "mean_c = mean_c['compound']\n",
    "\n",
    "# Plot a bar chart with pandas\n",
    "mean_c.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of headlines in scored_news (store as integer)\n",
    "num_news_before = len(scored_news['headline'])\n",
    "print(num_news_before)\n",
    "\n",
    "# Drop duplicates based on ticker and headline\n",
    "scored_news_clean = scored_news.drop_duplicates(subset=['ticker','headline'])\n",
    "\n",
    "# Count number of headlines after dropping duplicates\n",
    "num_news_after = len(scored_news_clean['headline'])\n",
    "print(num_news_after)\n",
    "\n",
    "# Print before and after numbers to get an idea of how we did \n",
    "f\"Before we had {num_news_before} headlines, now we have {num_news_after}\"\n",
    "\n",
    "500\n",
    "476\n",
    "\n",
    "'Before we had 500 headlines, now we have 476'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index to ticker and date\n",
    "single_day = scored_news_clean.set_index(['ticker', 'date'])\n",
    "\n",
    "# Cross-section the fb row\n",
    "single_day = single_day.loc['fb']\n",
    "\n",
    "# Select the 3rd of January of 2019\n",
    "single_day = single_day.loc['2019-01-03']\n",
    "\n",
    "# Convert the datetime string to just the time\n",
    "single_day['time'] = pd.to_datetime(single_day.time).dt.time\n",
    "\n",
    "# Set the index to time and \n",
    "single_day = single_day.set_index('time')\n",
    "\n",
    "# Sort it\n",
    "single_day = single_day.sort_index()\n",
    "print(single_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE = \"Negative, neutral, and positive sentiment for FB on 2019-01-03\"\n",
    "COLORS = [\"red\",\"orange\", \"green\"]\n",
    "\n",
    "# Drop the columns that aren't useful for the plot\n",
    "plot_day = single_day.drop(['headline','compound'], axis=1)\n",
    "\n",
    "# Change the column names to 'negative', 'positive', and 'neutral'\n",
    "plot_day.columns = ['negative', 'positive', 'neutral']\n",
    "\n",
    "# Plot a stacked bar chart for a single day 2019-01-03\n",
    "plot_day.plot.bar(stacked=True, figsize=(10,6), title=TITLE, color=COLORS).legend(bbox_to_anchor=(1.2,0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
